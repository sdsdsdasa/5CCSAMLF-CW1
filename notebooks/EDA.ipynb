{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ffc31fd",
   "metadata": {},
   "source": [
    "# EDA (Exploratory Data Analysis) with graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd8a7af",
   "metadata": {},
   "source": [
    "## Imports & settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c35cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (10000, 31)\n",
      "Test shape: (1000, 30)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "plt.rcParams[\"savefig.dpi\"] = 300\n",
    "\n",
    "\n",
    "# Find root automatically\n",
    "root = Path.cwd()\n",
    "while root.name != \"5CCSAMLF-CW1\":\n",
    "    if root.parent == root:\n",
    "        raise RuntimeError(\"5CCSAMLF-CW1 folder not found. Make sure you are inside the 5CCSAMLF-CW1 folder.\")\n",
    "    root = root.parent\n",
    "\n",
    "\n",
    "FIG_DIR = root / \"report\" / \"figures\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_PATH = root / \"data\" / \"CW1_train.csv\"\n",
    "TEST_PATH  = root / \"data\" / \"CW1_test.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49379d9",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b543b969",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/CW1_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trn = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m tst = pd.read_csv(TEST_PATH)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrain shape:\u001b[39m\u001b[33m\"\u001b[39m, trn.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TAO\\Desktop\\5CCSAMLF2\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:873\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, skip_blank_lines, parse_dates, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    861\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    862\u001b[39m     dialect,\n\u001b[32m    863\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    869\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    870\u001b[39m )\n\u001b[32m    871\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TAO\\Desktop\\5CCSAMLF2\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:300\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    297\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    299\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TAO\\Desktop\\5CCSAMLF2\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1645\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1642\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1644\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1645\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TAO\\Desktop\\5CCSAMLF2\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1904\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1902\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1903\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1904\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1905\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1911\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1913\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1914\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1915\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TAO\\Desktop\\5CCSAMLF2\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:926\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    922\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    923\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    935\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/CW1_train.csv'"
     ]
    }
   ],
   "source": [
    "trn = pd.read_csv(TRAIN_PATH)\n",
    "tst = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(\"Train shape:\", trn.shape)\n",
    "print(\"Test shape: \", tst.shape)\n",
    "\n",
    "display(trn.head())\n",
    "display(tst.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbf9d02",
   "metadata": {},
   "source": [
    "## Basic schema checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa0e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"outcome\"\n",
    "categorical_cols = [\"cut\", \"color\", \"clarity\"]\n",
    "\n",
    "assert target in trn.columns, \"Target 'outcome' not found in train!\"\n",
    "assert target not in tst.columns, \"Test should NOT contain 'outcome'!\"\n",
    "\n",
    "print(\"Train columns:\", len(trn.columns))\n",
    "print(\"Test columns: \", len(tst.columns))\n",
    "\n",
    "print(\"\\nTrain dtypes:\")\n",
    "display(trn.dtypes.value_counts())\n",
    "display(trn.dtypes)\n",
    "\n",
    "print(\"\\nMissing values (train):\")\n",
    "display(trn.isna().sum().sort_values(ascending=False).head(20))\n",
    "\n",
    "print(\"\\nMissing values (test):\")\n",
    "display(tst.isna().sum().sort_values(ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f37188e",
   "metadata": {},
   "source": [
    "## Quick descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(trn.describe(include=\"all\").T.head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b1aa35",
   "metadata": {},
   "source": [
    "## Identify numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9bfe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [c for c in trn.columns if c not in categorical_cols + [target]]\n",
    "num_train = trn[numeric_cols]\n",
    "num_test  = tst[numeric_cols]\n",
    "\n",
    "print(\"Numeric feature count:\", len(numeric_cols))\n",
    "print(\"Categorical features:\", categorical_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c2172",
   "metadata": {},
   "source": [
    "## Duplicate rows check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_count = trn.duplicated().sum()\n",
    "print(\"Duplicate rows in train:\", dup_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca462dec",
   "metadata": {},
   "source": [
    "## Target (outcome) distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f25704",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = trn[target]\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(y, bins=40)\n",
    "plt.title(\"Outcome distribution (train)\")\n",
    "plt.xlabel(\"outcome\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, \"outcome_hist.png\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"Outcome summary:\")\n",
    "display(y.describe())\n",
    "print(\"Skew:\", y.skew())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158baa07",
   "metadata": {},
   "source": [
    "## Categorical distributions + check levels in train vs test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2cbf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in categorical_cols:\n",
    "    plt.figure(figsize=(7,3))\n",
    "    trn[c].value_counts().plot(kind=\"bar\")\n",
    "    plt.title(f\"{c} frequency (train)\")\n",
    "    plt.xlabel(c)\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, f\"{c}_freq_train.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    train_levels = set(trn[c].dropna().unique())\n",
    "    test_levels  = set(tst[c].dropna().unique())\n",
    "    only_in_train = sorted(list(train_levels - test_levels))\n",
    "    only_in_test  = sorted(list(test_levels - train_levels))\n",
    "\n",
    "    print(f\"\\n[{c}] levels: train={len(train_levels)} test={len(test_levels)}\")\n",
    "    if only_in_train:\n",
    "        print(\"  Levels only in TRAIN:\", only_in_train)\n",
    "    if only_in_test:\n",
    "        print(\"  Levels only in TEST :\", only_in_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466a22b8",
   "metadata": {},
   "source": [
    "## Outcome by category (boxplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb55d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in categorical_cols:\n",
    "    groups = [trn.loc[trn[c] == level, target].values for level in trn[c].dropna().unique()]\n",
    "    labels = list(trn[c].dropna().unique())\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.boxplot(groups, labels=labels, showfliers=False)\n",
    "    plt.title(f\"Outcome by {c} (train)\")\n",
    "    plt.xlabel(c)\n",
    "    plt.ylabel(\"outcome\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, f\"outcome_by_{c}_box.png\"))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0932965f",
   "metadata": {},
   "source": [
    "## Numeric feature distributions (hist grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87950051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (This can be a lot; we chunk to avoid huge figures.)\n",
    "def hist_grid(df, cols, ncols=4, bins=30, title_prefix=\"\", save_name=None):\n",
    "    n = len(cols)\n",
    "    nrows = int(np.ceil(n / ncols))\n",
    "    plt.figure(figsize=(ncols*3.3, nrows*2.6))\n",
    "    for i, col in enumerate(cols, 1):\n",
    "        ax = plt.subplot(nrows, ncols, i)\n",
    "        ax.hist(df[col].dropna(), bins=bins)\n",
    "        ax.set_title(col, fontsize=9)\n",
    "        ax.tick_params(labelsize=8)\n",
    "    plt.suptitle(title_prefix, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    if save_name:\n",
    "        plt.savefig(os.path.join(FIG_DIR, save_name), bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# First 24 numeric cols\n",
    "hist_grid(num_train, numeric_cols[:24], title_prefix=\"Numeric feature distributions (subset)\", save_name=\"numeric_hist_subset1.png\")\n",
    "\n",
    "# Next 24 numeric cols (if exist)\n",
    "if len(numeric_cols) > 24:\n",
    "    hist_grid(num_train, numeric_cols[24:48], title_prefix=\"Numeric feature distributions (subset)\", save_name=\"numeric_hist_subset2.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30621d6f",
   "metadata": {},
   "source": [
    "## Correlation with target (numeric only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b17b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = trn[numeric_cols + [target]].corr(numeric_only=True)[target].drop(target).sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "display(corr.head(20))\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "corr.head(20).sort_values().plot(kind=\"barh\")\n",
    "plt.title(\"Top 20 numeric correlations with outcome (train)\")\n",
    "plt.xlabel(\"Pearson correlation\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, \"top_corr_with_outcome.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b48ab",
   "metadata": {},
   "source": [
    "## Correlation heatmap (top correlated numeric features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec91a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "topN = 18\n",
    "top_feats = list(corr.index[:topN])\n",
    "C = trn[top_feats + [target]].corr(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(C.values, aspect=\"auto\")\n",
    "plt.xticks(range(len(C.columns)), C.columns, rotation=90, fontsize=8)\n",
    "plt.yticks(range(len(C.index)), C.index, fontsize=8)\n",
    "plt.colorbar()\n",
    "plt.title(f\"Correlation heatmap (top {topN} + outcome)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, \"corr_heatmap_top.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e98363c",
   "metadata": {},
   "source": [
    "## Scatter plots vs outcome for top correlated numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc91b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_scatter = top_feats[:6]\n",
    "\n",
    "for col in top_scatter:\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.scatter(trn[col], trn[target], s=8, alpha=0.35)\n",
    "    plt.title(f\"Outcome vs {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"outcome\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, f\"scatter_outcome_{col}.png\"))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8580c8",
   "metadata": {},
   "source": [
    "## Outlier check (IQR) for key numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c8080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = [\"carat\", \"price\", \"x\", \"y\", \"z\", \"depth\", \"table\"]\n",
    "key_cols = [c for c in key_cols if c in numeric_cols]\n",
    "\n",
    "def iqr_outlier_rate(s: pd.Series) -> float:\n",
    "    q1 = s.quantile(0.25)\n",
    "    q3 = s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lo = q1 - 1.5 * iqr\n",
    "    hi = q3 + 1.5 * iqr\n",
    "    return ((s < lo) | (s > hi)).mean()\n",
    "\n",
    "outlier_rates = {c: iqr_outlier_rate(trn[c].dropna()) for c in key_cols}\n",
    "display(pd.Series(outlier_rates).sort_values(ascending=False))\n",
    "\n",
    "# Boxplots (hide fliers for readability)\n",
    "plt.figure(figsize=(9,4))\n",
    "trn[key_cols].plot(kind=\"box\", showfliers=False)\n",
    "plt.title(\"Key numeric features (boxplot, fliers hidden)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, \"key_numeric_boxplots.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a0e5c5",
   "metadata": {},
   "source": [
    "## Train vs Test distribution drift check (numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4001db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare mean/std quickly; big shifts might affect generalization.\n",
    "train_stats = num_train.describe().T[[\"mean\", \"std\", \"min\", \"max\"]]\n",
    "test_stats  = num_test.describe().T[[\"mean\", \"std\", \"min\", \"max\"]]\n",
    "\n",
    "drift = train_stats.join(test_stats, lsuffix=\"_train\", rsuffix=\"_test\")\n",
    "drift[\"mean_diff\"] = drift[\"mean_test\"] - drift[\"mean_train\"]\n",
    "drift[\"std_diff\"]  = drift[\"std_test\"] - drift[\"std_train\"]\n",
    "\n",
    "display(drift.sort_values(\"mean_diff\", key=lambda s: s.abs(), ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad20614c",
   "metadata": {},
   "source": [
    "## Train vs Test: quick overlay hist for a few important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_cols = [\"carat\", \"price\", \"x\", \"y\", \"z\"]\n",
    "compare_cols = [c for c in compare_cols if c in numeric_cols]\n",
    "\n",
    "for c in compare_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(num_train[c].dropna(), bins=40, alpha=0.5, label=\"train\")\n",
    "    plt.hist(num_test[c].dropna(),  bins=40, alpha=0.5, label=\"test\")\n",
    "    plt.title(f\"Train vs Test distribution: {c}\")\n",
    "    plt.xlabel(c)\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, f\"train_vs_test_{c}.png\"))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f620cd",
   "metadata": {},
   "source": [
    "## Report Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56db312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"train_rows\": trn.shape[0],\n",
    "    \"train_cols\": trn.shape[1],\n",
    "    \"test_rows\": tst.shape[0],\n",
    "    \"test_cols\": tst.shape[1],\n",
    "    \"missing_train_total\": int(trn.isna().sum().sum()),\n",
    "    \"missing_test_total\": int(tst.isna().sum().sum()),\n",
    "    \"dup_rows_train\": int(trn.duplicated().sum()),\n",
    "    \"outcome_mean\": float(trn[target].mean()),\n",
    "    \"outcome_std\": float(trn[target].std()),\n",
    "    \"outcome_skew\": float(trn[target].skew()),\n",
    "}\n",
    "\n",
    "print(summary)\n",
    "\n",
    "print(\"\\nTop 10 numeric correlations with outcome:\")\n",
    "display(corr.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
